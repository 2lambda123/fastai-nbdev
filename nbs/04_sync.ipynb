{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp sync"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synchronize and diff\n",
    "\n",
    "> Propagating small changes in the library back to notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The library is primarily developed in notebooks so any big changes should be made there. But sometimes, it's easier to fix small bugs or typos in the modules directly. `nbprocess_update_lib` is the function that will propagate those changes back to the corresponding notebooks. Note that you can't create new cells or reorder cells with that functionality, so your corrections should remain limited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from nbprocess.imports import *\n",
    "from nbprocess.read import *\n",
    "from nbprocess.maker import *\n",
    "from nbprocess.process import *\n",
    "from nbprocess.export import *\n",
    "\n",
    "from fastcore.script import *\n",
    "from fastcore.xtras import *\n",
    "\n",
    "import ast,tempfile,json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from pdb import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def nb2dict(d, k=None):\n",
    "    \"Convert parsed notebook to `dict`\"\n",
    "    if k in ('source',): return d.splitlines(keepends=True)\n",
    "    if isinstance(d, (L,list)): return list(L(d).map(nb2dict))\n",
    "    if not isinstance(d, dict): return d\n",
    "    return dict(**{k:nb2dict(v,k) for k,v in d.items() if k[-1] != '_'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns the exact same dict as is read from the notebook JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimal_fn = Path('../tests/minimal.ipynb')\n",
    "minimal = read_nb(minimal_fn)\n",
    "\n",
    "minimal_dict = minimal_fn.read_json()\n",
    "assert minimal_dict==nb2dict(minimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def write_nb(nb, path):\n",
    "    \"Write `nb` to `path`\"\n",
    "    if isinstance(nb, (AttrDict,L)): nb = nb2dict(nb)\n",
    "    with maybe_open(path, 'w', encoding='utf-8') as f:\n",
    "        f.write(json.dumps(nb, sort_keys=True, indent=1, ensure_ascii=False))\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns the exact same string as saved by Jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = Path('tmp.ipynb')\n",
    "try:\n",
    "    minimal_txt = minimal_fn.read_text()\n",
    "    write_nb(minimal, tmp)\n",
    "    assert minimal_txt==tmp.read_text()\n",
    "finally: tmp.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def absolute_import(name, fname, level):\n",
    "    \"Unwarps a relative import in `name` according to `fname`\"\n",
    "    if not level: return name\n",
    "    mods = fname.split(os.path.sep)\n",
    "    if not name: return '.'.join(mods)\n",
    "    return '.'.join(mods[:len(mods)-level+1]) + f\".{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(absolute_import('xyz', 'nbprocess', 0), 'xyz')\n",
    "test_eq(absolute_import('', 'nbprocess', 1), 'nbprocess')\n",
    "test_eq(absolute_import('core', 'nbprocess', 1), 'nbprocess.core')\n",
    "test_eq(absolute_import('core', 'nbprocess/vision', 2), 'nbprocess.core')\n",
    "test_eq(absolute_import('transform', 'nbprocess/vision', 1), 'nbprocess.vision.transform')\n",
    "test_eq(absolute_import('notebook.core', 'nbprocess/data', 2), 'nbprocess.notebook.core')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "_re_import = re.compile(\"from\\s+\\S+\\s+import\\s+\\S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "assert _re_import.match('from foo import bar')\n",
    "assert not _re_import.match('#from foo import bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def _to_absolute(code, lib_name):\n",
    "    if not _re_import.search(code): return code\n",
    "    res = update_import(code, ast.parse(code).body, lib_name, absolute_import)\n",
    "    return ''.join(res) if res else code\n",
    "\n",
    "def _update_lib(nbname, nb_locs, lib_name=None):\n",
    "    if lib_name is None: lib_name = get_config().lib_name\n",
    "    nbp = NBProcessor(nbname, ExportModuleProc(), rm_directives=False)\n",
    "    nb = nbp.nb\n",
    "    nbp.process()\n",
    "\n",
    "    for name,idx,code in nb_locs:\n",
    "        assert name==nbname\n",
    "        cell = nb.cells[int(idx)-1]\n",
    "        lines = cell.source.splitlines(True)\n",
    "        directives = ''.join(cell.source.splitlines(True)[:len(cell.directives_)])\n",
    "        cell.source = source + _to_absolute(code, lib_name)\n",
    "    write_nb(nb, nbname)\n",
    "\n",
    "def _get_call(s):\n",
    "    top,*rest = s.splitlines()\n",
    "    return *top.split(),'\\n'.join(rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@call_parse\n",
    "def update_lib(fname:str): # A python file name to convert\n",
    "    \"Propagates any change in the modules matching `fname` to the notebooks that created them\"\n",
    "    if os.environ.get('IN_TEST',0): return\n",
    "    code_cells = Path(fname).read_text().split(\"\\n# %% \")[1:]\n",
    "    locs = L(_get_call(s) for s in code_cells if not s.startswith('auto '))\n",
    "    for nbname,nb_locs in groupby(locs, 0).items(): _update_lib(nbname, nb_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "# update_lib(\"../nbprocess/sync.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|skip\n",
    "from nbprocess.export import nbs_export\n",
    "nbs_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
