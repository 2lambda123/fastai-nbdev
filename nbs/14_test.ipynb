{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2022982-581f-4b0c-87cc-5a0f977da3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac1573c0-bcfc-4912-823d-508d75bf79d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import time,os,sys,traceback,contextlib, inspect\n",
    "from fastcore.basics import *\n",
    "from fastcore.imports import *\n",
    "from fastcore.foundation import *\n",
    "from fastcore.parallel import *\n",
    "from fastcore.script import *\n",
    "\n",
    "from nbprocess.read import *\n",
    "from nbprocess.doclinks import *\n",
    "from nbprocess.process import NBProcessor\n",
    "from logging import warning\n",
    "\n",
    "from execnb.nbio import *\n",
    "from execnb.shell import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2084506e-4393-41eb-8057-9406e78e4079",
   "metadata": {},
   "source": [
    "# Test Notebooks\n",
    "> Run unit tests on notebooks in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f4fa1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def test_nb(fn, skip_flags=None, force_flags=None, do_print=False, showerr=True):\n",
    "    \"Execute tests in notebook in `fn` except those with `skip_flags`\"\n",
    "    if not IN_NOTEBOOK: os.environ[\"IN_TEST\"] = '1'\n",
    "    flags=set(L(skip_flags)) - set(L(force_flags))\n",
    "    nb = NBProcessor(fn, process=True).nb\n",
    "\n",
    "    def _no_eval(cell):\n",
    "        if cell.cell_type != 'code': return True\n",
    "        direc = getattr(cell, 'directives_', {}) or {}\n",
    "        if direc.get('eval:', [''])[0].lower() == 'false': return True\n",
    "        return flags & direc.keys()\n",
    "    \n",
    "    start = time.time()\n",
    "    k = CaptureShell(fn)\n",
    "    if do_print: print(f'Starting {fn}')\n",
    "    try:\n",
    "        k.run_all(nb, exc_stop=True, preproc=_no_eval)\n",
    "        res = True\n",
    "    except: \n",
    "        if showerr: warning(k.prettytb(fname=fn))\n",
    "        res=False\n",
    "    if do_print: print(f'- Completed {fn}')\n",
    "    return res,time.time()-start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc26b80-6e4e-4a16-bcde-dd4d156289e5",
   "metadata": {},
   "source": [
    "`test_nb` can test a notebook, and skip over certain flags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0cf84ef-bce4-4531-80df-7a4e514a7ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03224658966064453"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_nb = Path('../tests/directives.ipynb')\n",
    "success,duration = test_nb(_nb, skip_flags=['notest'])\n",
    "assert success\n",
    "duration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46117f38",
   "metadata": {},
   "source": [
    "In that notebook the cell flagged *notest* raises an exception, which will be returned as a `bool`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f521b5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "_nb = Path('../tests/directives.ipynb')\n",
    "success,duration = test_nb(_nb, showerr=False)\n",
    "assert not success"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ef30c3-38ee-4c77-93df-c1ae4f959eb1",
   "metadata": {},
   "source": [
    "Sometimes you may wish to override one or more of the skip_flags, in which case you can use the argument `force_flags` which will remove the appropriate tag(s) from `skip_flags`.  This is useful because `skip_flags` are meant to be set in the `tst_flags` field of `settings.ini`, whereas `force_flags` are usually passed in by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8cc6a61-a48e-4ab1-89a9-18316ca795d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@call_parse\n",
    "def nbprocess_test(\n",
    "    fname:str=None,  # A notebook name or glob to convert\n",
    "    flags:str='',  # Space separated list of test flags you want to run that are normally ignored\n",
    "    n_workers:int=None,  # Number of workers to use\n",
    "    timing:bool=False,  # Timing each notebook to see the ones are slow\n",
    "    do_print:str=False, # Print start and end of each NB\n",
    "    pause:float=0.01  # Pause time (in secs) between notebooks to avoid race conditions\n",
    "):\n",
    "    \"Test in parallel the notebooks matching `fname`, passing along `flags`\"\n",
    "    skip_flags = config_key('tst_flags', '', path=False).split()\n",
    "    force_flags = flags.split()\n",
    "    files = [Path(f).absolute() for f in sorted(nbglob(fname))]\n",
    "    if n_workers is None: n_workers = 0 if len(files)==1 else min(num_cpus(), 8)\n",
    "    os.chdir(config_key(\"nbs_path\"))\n",
    "    results = parallel(test_nb, files, skip_flags=skip_flags, force_flags=force_flags, n_workers=n_workers, pause=pause, do_print=do_print)\n",
    "    passed,times = zip(*results)\n",
    "    if all(passed): print(\"Success.\")\n",
    "    else: \n",
    "        _fence = '='*50\n",
    "        failed = '\\n\\t'.join(f.name for p,f in zip(passed,files) if not p)\n",
    "        sys.stderr.write(f\"\\nnbprocess Tests Failed On The Following Notebooks:\\n{_fence}\\n\\t{failed}\")\n",
    "        exit(1)\n",
    "    if timing:\n",
    "        for i,t in sorted(enumerate(times), key=lambda o:o[1], reverse=True): print(f\"{files[i].name}: {int(t)} secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a6e0542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success.\n"
     ]
    }
   ],
   "source": [
    "#|eval:false\n",
    "nbprocess_test(n_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee3f4db",
   "metadata": {},
   "source": [
    "## Eval -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "267a32f1-8884-497e-a1af-dd38c80d8873",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from nbprocess.doclinks import nbprocess_export\n",
    "nbprocess_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f62c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
