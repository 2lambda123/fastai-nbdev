{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Clean\n",
    "description: Strip superfluous metadata from notebooks\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "#|default_exp clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import json,warnings,stat\n",
    "\n",
    "from fastcore.script import *\n",
    "from fastcore.utils import *\n",
    "from fastcore.imports import *\n",
    "\n",
    "from nbprocess.imports import *\n",
    "from nbprocess.read import *\n",
    "from nbprocess.sync import *\n",
    "from nbprocess.cli import config_key\n",
    "from nbprocess.process import first_code_ln"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid pointless conflicts while working with jupyter notebooks (with different execution counts or cell metadata), it is recommended to clean the notebooks before committing anything (done automatically if you install the git hooks with `nbprocess_install_git_hooks`). The following functions are used to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@call_parse\n",
    "def nbprocess_trust(\n",
    "    fname:str=None,  # A notebook name or glob to trust\n",
    "    force_all:bool=False  # Trust even notebooks that havent changed\n",
    "):\n",
    "    \"Trust notebooks matching `fname`\"\n",
    "    try: from nbformat.sign import NotebookNotary\n",
    "    except:\n",
    "        import warnings\n",
    "        warnings.warn(\"Please install jupyter and try again\")\n",
    "        return\n",
    "\n",
    "    fname = Path(fname if fname else config_key(\"nbs_path\", '.'))\n",
    "    path = fname if fname.is_dir() else fname.parent\n",
    "    check_fname = path/\".last_checked\"\n",
    "    last_checked = os.path.getmtime(check_fname) if check_fname.exists() else None\n",
    "    nbs = globtastic(fname, file_glob='*.ipynb', skip_folder_re='^[_.]') if fname.is_dir() else [fname]\n",
    "    for fn in nbs:\n",
    "        if last_checked and not force_all:\n",
    "            last_changed = os.path.getmtime(fn)\n",
    "            if last_changed < last_checked: continue\n",
    "        nb = read_nb(fn)\n",
    "        if not NotebookNotary().check_signature(nb): NotebookNotary().sign(nb)\n",
    "    check_fname.touch(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def _re_v1():\n",
    "    d = ['default_exp', 'export', 'exports', 'exporti', 'hide', 'hide_input', 'collapse_show', \n",
    "         'collapse_hide', 'hide_output', 'collapse_input', 'collapse_output', 'default_cls_lvl']\n",
    "    d += L(get_config().get('tst_flags', []))\n",
    "    d += [s.replace('_', '-') for s in d] # allow for hyphenated version of old directives\n",
    "    _tmp = '|'.join(list(set(d)))\n",
    "    return re.compile(f\"^[ \\f\\v\\t]*?(#)\\s*({_tmp})\", re.MULTILINE)\n",
    "\n",
    "def _repl_directives(code_str): \n",
    "    def _fmt(x): return f\"#|{x.group(2).replace('-', '_')}\"\n",
    "    return _re_v1().sub(_fmt, code_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "_test_dir = \"\"\"\n",
    "#default_exp\n",
    " #export\n",
    "# collapse-show\n",
    "#collapse-hide\n",
    "#collapse-output\n",
    "# collapse_output\n",
    "not_dir='#export'\n",
    "# hide_input\n",
    "foo\n",
    "\"\"\"\n",
    "test_eq(_repl_directives(_test_dir), \"\\n#|default_exp\\n#|export\\n#|collapse_show\\n#|collapse_hide\\n#|collapse_output\\n#|collapse_output\\nnot_dir='#export'\\n#|hide_input\\nfoo\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def repl_v1dir(nb):\n",
    "    \"Replace nbdev v1 with v2 directives.\"\n",
    "    for cell in nb['cells']:\n",
    "        if cell.get('source') and cell.get('cell_type') == 'code':\n",
    "            ss = cell['source'].copy()\n",
    "            first_code = first_code_ln(ss, re_pattern=_re_v1())\n",
    "            if not first_code: first_code = len(ss)\n",
    "            if not ss: pass\n",
    "            else: cell['source'] = [_repl_directives(c) for c in ss[:first_code]] + ss[first_code:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_code = _test_dir.splitlines(True)\n",
    "\n",
    "tst = {'cell_type': 'code', 'execution_count': 26,\n",
    "       'metadata': {'hide_input': True, 'meta': 23},\n",
    "       'outputs': [{'execution_count': 2,\n",
    "                    'data': {\n",
    "                        'application/vnd.google.colaboratory.intrinsic+json': {'type': 'string'},\n",
    "                        'plain/text': ['sample output',]\n",
    "                    }, 'output': 'super'}],\n",
    "       'source': _code}\n",
    "nb = {'metadata': {'kernelspec': 'some_spec', 'jekyll': 'some_meta', 'meta': 37}, 'cells': [tst]}\n",
    "\n",
    "repl_v1dir(nb)\n",
    "test_eq(nb['cells'][0], {'cell_type': 'code',\n",
    "     'execution_count': 26,\n",
    "     'metadata': {'hide_input': True, 'meta': 23},\n",
    "     'outputs': [{'execution_count': 2,\n",
    "     'data': {'application/vnd.google.colaboratory.intrinsic+json': {'type': 'string'},\n",
    "     'plain/text': ['sample output']},\n",
    "     'output': 'super'}],\n",
    "     'source': ['\\n', '#|default_exp\\n', '#|export\\n', '#|collapse_show\\n', '#|collapse_hide\\n', '#|collapse_output\\n', '#|collapse_output\\n', \"not_dir='#export'\\n\", '# hide_input\\n', 'foo\\n']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def _clean_cell_output(cell):\n",
    "    \"Remove execution count in `cell`\"\n",
    "    if 'outputs' in cell:\n",
    "        for o in cell['outputs']:\n",
    "            if 'execution_count' in o: o['execution_count'] = None\n",
    "            o.get('data',{}).pop(\"application/vnd.google.colaboratory.intrinsic+json\", None)\n",
    "            o.get('metadata', {}).pop('tags', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def _clean_cell(cell, clear_all=False):\n",
    "    \"Clean `cell` by removing superfluous metadata or everything except the input if `clear_all`\"\n",
    "    if 'execution_count' in cell: cell['execution_count'] = None\n",
    "    if 'outputs' in cell:\n",
    "        if clear_all: cell['outputs'] = []\n",
    "        else:         _clean_cell_output(cell)\n",
    "    if cell['source'] == ['']: cell['source'] = []\n",
    "    cell['metadata'] = {} if clear_all else {\n",
    "        k:v for k,v in cell['metadata'].items() if k==\"hide_input\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def clean_nb(nb, clear_all=False):\n",
    "    \"Clean `nb` from superfluous metadata\"\n",
    "    for c in nb['cells']: _clean_cell(c, clear_all=clear_all)\n",
    "    nb['metadata'] = {k:v for k,v in nb['metadata'].items() if k in\n",
    "                     (\"kernelspec\", \"jekyll\", \"jupytext\", \"doc\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = {'cell_type': 'code', 'execution_count': 26,\n",
    "       'metadata': {'hide_input': True, 'meta': 23},\n",
    "       'outputs': [{'execution_count': 2,\n",
    "                    'data': {\n",
    "                        'application/vnd.google.colaboratory.intrinsic+json': {'type': 'string'},\n",
    "                        'plain/text': ['sample output',]\n",
    "                    }, 'output': 'super'}],\n",
    "       'source': 'awesome_code'}\n",
    "nb = {'metadata': {'kernelspec': 'some_spec', 'jekyll': 'some_meta', 'meta': 37}, 'cells': [tst]}\n",
    "\n",
    "clean_nb(nb)\n",
    "test_eq(nb['cells'][0], {'cell_type': 'code', 'execution_count': None,\n",
    "              'metadata': {'hide_input': True},\n",
    "              'outputs': [{'execution_count': None, \n",
    "                           'data': { 'plain/text': ['sample output',]},\n",
    "                           'output': 'super'}],\n",
    "              'source': 'awesome_code'})\n",
    "test_eq(nb['metadata'], {'kernelspec': 'some_spec', 'jekyll': 'some_meta'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clean_nbs -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def _wrapio(strm): return io.TextIOWrapper(strm.buffer, encoding='utf-8', line_buffering=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def _process_write(warn_msg, proc_nb, f_in, f_out=None, disp=False):\n",
    "    if not f_out: f_out = _wrapio(sys.stdout) if disp else f_in\n",
    "    if isinstance(f_in, (str,Path)): f_in = Path(f_in).open()\n",
    "    try:\n",
    "        nb = json.load(f_in)\n",
    "        proc_nb(nb)\n",
    "        write_nb(nb, f_out)\n",
    "    except Exception as e:\n",
    "        warn(f'{warn_msg}')\n",
    "        warn(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@call_parse\n",
    "def nbprocess_clean(\n",
    "    fname:str=None, # A notebook name or glob to convert\n",
    "    clear_all:bool=False, # Clean all metadata and outputs\n",
    "    disp:bool=False,  # Print the cleaned outputs\n",
    "    stdin:bool=False # Read input stream and not nb folder\n",
    "):\n",
    "    \"Clean all notebooks in `fname` to avoid merge conflicts\"\n",
    "    # Git hooks will pass the notebooks in stdin\n",
    "    _clean = partial(clean_nb, clear_all=clear_all)\n",
    "    _write = partial(_process_write, warn_msg='Failed to clean notebook', proc_nb=_clean)\n",
    "    if stdin: _write(f_in=_wrapio(sys.stdin), f_out=_wrapio(sys.stdout))\n",
    "    \n",
    "    if fname is None: fname = config_key(\"nbs_path\", '.')\n",
    "    for f in globtastic(fname, file_glob='*.ipynb', skip_folder_re='^[_.]'): _write(f_in=f, disp=disp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default (`fname` left to `None`), the all the notebooks in `lib_folder` are cleaned. You can opt in to fully clean the notebook by removing every bit of metadata and the cell outputs by passing `clear_all=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@call_parse\n",
    "def nbprocess_migrate_directives(\n",
    "    fname:str=None, # A notebook name or glob to convert\n",
    "    disp:bool=False,  # Print the outputs with newly formatted directives\n",
    "    stdin:bool=False # Read input stream and not nb folder\n",
    "):\n",
    "    \"Convert all directives from v1 to v2 in `fname`.\"\n",
    "    _write = partial(_process_write, warn_msg='Failed to replace directives', proc_nb=repl_v1dir)\n",
    "    if stdin: _write(f_in=_wrapio(sys.stdin), f_out=_wrapio(sys.stdout))\n",
    "    \n",
    "    if fname is None: fname = config_key(\"nbs_path\", '.')\n",
    "    for f in globtastic(fname, file_glob='*.ipynb', skip_folder_re='^[_.]'): _write(f_in=f, disp=disp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@call_parse\n",
    "def nbprocess_install_hooks():\n",
    "    \"Install git hooks to clean/trust notebooks automatically\"\n",
    "    nb_path = config_key(\"nbs_path\", '.')\n",
    "    path = get_config().config_path\n",
    "    hook_path = path/'.git'/'hooks'\n",
    "    fn = hook_path/'post-merge'\n",
    "    hook_path.mkdir(parents=True, exist_ok=True)\n",
    "    fn.write_text(\"#!/bin/bash\\nnbprocess_trust\")\n",
    "    os.chmod(fn, os.stat(fn).st_mode | stat.S_IEXEC)\n",
    "    #Clean notebooks on commit/diff\n",
    "    (path/'.gitconfig').write_text(\"\"\"# Generated by nbprocess_install_git_hooks\n",
    "#\n",
    "# If you need to disable this instrumentation do:\n",
    "#   git config --local --unset include.path\n",
    "#\n",
    "# To restore the filter\n",
    "#   git config --local include.path .gitconfig\n",
    "#\n",
    "# If you see notebooks not stripped, checked the filters are applied in .gitattributes\n",
    "#\n",
    "[filter \"clean-nbs\"]\n",
    "        clean = nbprocess_clean --stdin\n",
    "        smudge = cat\n",
    "        required = true\n",
    "[diff \"ipynb\"]\n",
    "        textconv = nbprocess_clean --disp --fname\n",
    "\"\"\")\n",
    "    cmd = \"git config --local include.path ../.gitconfig\"\n",
    "    run(cmd)\n",
    "    print(\"Hooks are installed and repo's .gitconfig is now trusted\")\n",
    "    (nb_path/'.gitattributes').write_text(\"**/*.ipynb filter=clean-nbs\\n**/*.ipynb diff=ipynb\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval:false\n",
    "from nbprocess.doclinks import nbprocess_export\n",
    "nbprocess_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
